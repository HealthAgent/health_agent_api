import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
from sidebar import render_sidebar
from sql_mountain_service import SQLMountainService
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Streamlit ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="ë‹¹ì‹ ì€ ë‚˜ì˜ ë“±ë°˜ì", page_icon="ğŸ”ï¸", layout="wide")
st.title("ë‹¹ì‹ ì€ ë‚˜ì˜ ë“±ë°˜ì ğŸ”ï¸")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

if "api_key_valid" not in st.session_state:
    st.session_state.api_key_valid = False

# ì‚° ì •ë³´ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ)
if "mountain_service" not in st.session_state:
    st.session_state.mountain_service = SQLMountainService()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "last_mountain" not in st.session_state:
    st.session_state.last_mountain = None


# ì‚¬ì´ë“œë°” ë Œë”ë§
render_sidebar()

# API í‚¤ í™•ì¸
if not st.session_state.api_key_valid:
    st.warning("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

# LLM ì„¤ì •
llm = ChatOpenAI(
    api_key=st.session_state.openai_api_key,
    model="gpt-4o-mini",
    temperature=0.7
)

# ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥
if user_input := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ìƒê° ì¤‘..."):
            try:
                # ëŒ€í™” ê¸°ë¡ì„ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì‚° ì •ë³´ ì„œë¹„ìŠ¤ìš©)
                conversation_history = [msg["content"] for msg in st.session_state.messages]
                
                # 1ë‹¨ê³„: ì‚° ì •ë³´ ì„œë¹„ìŠ¤ë¡œ ë¨¼ì € ì²˜ë¦¬ ì‹œë„
                mountain_response = st.session_state.mountain_service.process_query(
                    user_input, 
                    conversation_history[:-1]  # í˜„ì¬ ì…ë ¥ ì œì™¸í•œ ì´ì „ ëŒ€í™”ë“¤
                )
                
                if mountain_response:
                    # ì‚° ê´€ë ¨ ì§ˆë¬¸ì´ë©´ ì‚° ì •ë³´ ì„œë¹„ìŠ¤ ì‘ë‹µ ì‚¬ìš©
                    response_content = mountain_response
                    logger.info("ì‚° ì •ë³´ ì„œë¹„ìŠ¤ë¡œ ì²˜ë¦¬ë¨")
                    
                else:
                    # ì‚° ê´€ë ¨ì´ ì•„ë‹ˆë©´ ì¼ë°˜ ì±—ë´‡ìœ¼ë¡œ ì²˜ë¦¬
                    logger.info("ì¼ë°˜ ì±—ë´‡ìœ¼ë¡œ ì²˜ë¦¬ë¨")
                    
                    # ëŒ€í™” ê¸°ë¡ì„ LangChain ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    messages = []
                    for msg in st.session_state.messages:
                        if msg["role"] == "user":
                            messages.append(HumanMessage(content=msg["content"]))
                        else:
                            messages.append(AIMessage(content=msg["content"]))
                    
                    # AI ì‘ë‹µ ìƒì„±
                    response = llm.invoke(messages)
                    response_content = response.content
                
                # ì‘ë‹µ í‘œì‹œ
                st.markdown(response_content)
                
                # ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
                st.session_state.messages.append({"role": "assistant", "content": response_content})
                
            except Exception as e:
                error_message = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                st.error(error_message)
                st.session_state.messages.append({"role": "assistant", "content": error_message})
                logger.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")