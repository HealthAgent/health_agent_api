import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain.tools import Tool
from langchain.memory import ConversationBufferMemory
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from utils import render_with_latex
from sidebar import render_gear_sidebar
from database import Database
import os
import json

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”

# ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# í˜„ì¬ ëŒ€í™” ì„¸ì…˜ IDê°€ ì—†ìœ¼ë©´ Noneë¡œ ì´ˆê¸°í™”
if "current_conversation_id" not in st.session_state:
    st.session_state.current_conversation_id = None

# API í‚¤ ìœ íš¨ì„± ê²€ì¦ ìƒíƒœê°€ ì—†ìœ¼ë©´ Falseë¡œ ì´ˆê¸°í™”
if "api_key_valid" not in st.session_state:
    st.session_state.api_key_valid = False

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
db = Database()

# Streamlit ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="ë“±ì‚° ìš©í’ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ", page_icon="â›°ï¸", layout="wide")
st.title("â›°ï¸ ë“±ì‚° ìš©í’ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ")

# ì‚¬ì´ë“œë°” ë Œë”ë§
render_gear_sidebar()

# API í‚¤ ìœ íš¨ì„± ê²€ì¦ ìƒíƒœ í™•ì¸
if not st.session_state.api_key_valid:
    st.warning("OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ìœ íš¨í•œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()  # ì—¬ê¸°ì„œ ì‹¤í–‰ì„ ì¤‘ë‹¨í•˜ì—¬ ì±„íŒ… ê¸°ëŠ¥ ì œí•œ

# LangChain ì„¤ì •
try:
    api_key = st.session_state.get("openai_api_key", st.secrets.get("openai", {}).get("api_key", ""))
except Exception:
    api_key = st.session_state.get("openai_api_key", "")

if not api_key:
    st.warning("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

# LLM ì„¤ì •
llm = ChatOpenAI(
    api_key=api_key,
    model="gpt-4",
    temperature=0.7
)

# ì„ë² ë”© ì„¤ì •
embeddings = OpenAIEmbeddings(api_key=api_key)

# ë©”ëª¨ë¦¬ ì„¤ì •
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
prompt = ChatPromptTemplate.from_messages([
    ("system", """ë‹¹ì‹ ì€ ë“±ì‚° ìš©í’ˆ ê´€ë¦¬ë¥¼ ë„ì™€ì£¼ëŠ” ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ë“±ì‚° ìš©í’ˆì„ ê´€ë¦¬í•˜ê³  ì¡°ì–¸í•´ì£¼ì„¸ìš”.
    
    ê°€ëŠ¥í•œ ì‘ì—…:
    1. ìƒˆë¡œìš´ ë“±ì‚° ìš©í’ˆ ë“±ë¡
    2. ë“±ì‚° ìš©í’ˆ ëª©ë¡ ì¡°íšŒ
    3. ìš©í’ˆ ìƒíƒœ ì—…ë°ì´íŠ¸
    
    ì‚¬ìš© ê°€ëŠ¥í•œ íˆ´:
    {tools}
    
    {agent_scratchpad}
    """),
    ("human", "{input}")
])

# ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
agent_prompt = ChatPromptTemplate.from_messages([
    ("system", """ë‹¹ì‹ ì€ ë“±ì‚° ìš©í’ˆ ê´€ë¦¬ë¥¼ ë„ì™€ì£¼ëŠ” ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ë“±ì‚° ìš©í’ˆì„ ê´€ë¦¬í•˜ê³  ì¡°ì–¸í•´ì£¼ì„¸ìš”.
    
    ê°€ëŠ¥í•œ ì‘ì—…:
    1. ìƒˆë¡œìš´ ë“±ì‚° ìš©í’ˆ ë“±ë¡
    2. ë“±ì‚° ìš©í’ˆ ëª©ë¡ ì¡°íšŒ
    3. ìš©í’ˆ ìƒíƒœ ì—…ë°ì´íŠ¸
    
    ì‚¬ìš© ê°€ëŠ¥í•œ íˆ´:
    {tools}
    
    {agent_scratchpad}
    """),
    ("human", "{input}")
])

# ë“±ì‚° ìš©í’ˆ ê´€ë¦¬ íˆ´ ì •ì˜
def add_gear_tool(input_str: str) -> str:
    """ë“±ì‚° ìš©í’ˆ ì¶”ê°€ íˆ´"""
    try:
        data = json.loads(input_str)
        user = db.get_user(data['username'])
        if not user:
            return "ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        gear_id = db.add_hiking_gear(user[0], data)
        if gear_id:
            return f"ì„±ê³µì ìœ¼ë¡œ {data['item_name']}ì„(ë¥¼) ì¶”ê°€í–ˆìŠµë‹ˆë‹¤."
        return "ë“±ì‚° ìš©í’ˆ ì¶”ê°€ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def get_user_gear_tool(username: str) -> str:
    """ì‚¬ìš©ìì˜ ë“±ì‚° ìš©í’ˆ ëª©ë¡ ì¡°íšŒ íˆ´"""
    try:
        user = db.get_user(username)
        if not user:
            return "ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        items = db.get_user_gear(user[0])
        if not items:
            return "ë“±ë¡ëœ ë“±ì‚° ìš©í’ˆì´ ì—†ìŠµë‹ˆë‹¤."
        
        result = "ğŸ“‹ ë“±ì‚° ìš©í’ˆ ëª©ë¡:\n\n"
        current_category = None
        for item in items:
            if item[3] != current_category:
                current_category = item[3]
                result += f"\nã€{current_category}ã€‘\n"
            result += f"â€¢ {item[2]}"
            if item[4]:  # brand
                result += f" ({item[4]})"
            result += f" - {item[9]}\n"  # condition
        return result
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def update_condition_tool(input_str: str) -> str:
    """ë“±ì‚° ìš©í’ˆ ìƒíƒœ ì—…ë°ì´íŠ¸ íˆ´"""
    try:
        data = json.loads(input_str)
        if db.update_gear_condition(data['gear_id'], data['condition'], data.get('last_used_date')):
            return "ì¥ë¹„ ìƒíƒœê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤."
        return "ìƒíƒœ ì—…ë°ì´íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# íˆ´ ì„¤ì •
tools = [
    Tool(
        name="add_hiking_gear",
        func=add_gear_tool,
        description="ìƒˆë¡œìš´ ë“±ì‚° ìš©í’ˆì„ ì¶”ê°€í•©ë‹ˆë‹¤."
    ),
    Tool(
        name="get_user_gear",
        func=get_user_gear_tool,
        description="ì‚¬ìš©ìì˜ ë“±ì‚° ìš©í’ˆ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."
    ),
    Tool(
        name="update_gear_condition",
        func=update_condition_tool,
        description="ë“±ì‚° ìš©í’ˆì˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."
    )
]

# ì—ì´ì „íŠ¸ ì„¤ì •
agent = create_openai_functions_agent(llm, tools, agent_prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

# RAG ì„¤ì •
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)

# ë²¡í„° ìŠ¤í† ì–´ ì„¤ì • (ì‹¤ì œ ì‚¬ìš© ì‹œ ì£¼ì„ í•´ì œ)
# vectorstore = FAISS.from_texts(
#     texts=["ê±´ê°• ì •ë³´ ìƒ˜í”Œ 1", "ê±´ê°• ì •ë³´ ìƒ˜í”Œ 2"],
#     embedding=embeddings
# )

# ì²´ì¸ ì„¤ì •
chain = (
    {"input": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶œë ¥
if st.session_state.messages:
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            if msg["role"] == "assistant":
                st.markdown(render_with_latex(msg["content"]))
            else:
                st.markdown(msg["content"])

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")

if user_input:
    
    # í˜„ì¬ ëŒ€í™” ì„¸ì…˜ IDê°€ ì—†ìœ¼ë©´ ìƒì„±; ì²« ì¿¼ë¦¬ì˜ 10ìë§Œí¼ ì œëª©ìœ¼ë¡œ ì„¤ì •
    if not st.session_state.current_conversation_id:
        conversation_title = user_input[:10] + "..." if len(user_input) > 50 else user_input
        st.session_state.current_conversation_id = db.create_conversation(conversation_title)
        
        
    # ì‚¬ìš©ìì˜ ì²« ë²ˆì§¸ ì§ˆë¬¸ì„ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    st.chat_message("user").write(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})
    db.save_message(st.session_state.current_conversation_id, "user", user_input)

    with st.chat_message("assistant"):
        stream_placeholder = st.empty()
        full_response = ""

        try:
            # ì—ì´ì „íŠ¸ë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„± (ì£¼ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©)
            # response = agent_executor.invoke({"input": user_input})
            # full_response = response["output"]

            # ë˜ëŠ” ê¸°ë³¸ ì²´ì¸ì„ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„±
            for chunk in chain.stream(user_input):
                full_response += chunk
                stream_placeholder.markdown(render_with_latex(full_response + "â–Œ"))

            # ìµœì¢… ì‘ë‹µ í‘œì‹œ
            stream_placeholder.empty()
            st.markdown(render_with_latex(full_response))

            # ì‘ë‹µ ì €ì¥
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            db.save_message(st.session_state.current_conversation_id, "assistant", full_response)

        except Exception as e:
            st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.info("ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            st.stop()
